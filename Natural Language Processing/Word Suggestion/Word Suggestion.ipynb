{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS 631 CRN 24002 - Project 1\n",
        "\n",
        "### Group: Yash Kantharia, Poonam Adtani"
      ],
      "metadata": {
        "id": "oc6sRXjpZCx_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Hug2tTdcQdsT"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 : String Manipulations"
      ],
      "metadata": {
        "id": "FhcuPjRuQqLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_char(word):\n",
        "    del_words = []\n",
        "    for i in range(0,len(word)):\n",
        "      del_words.append(word[:i] + word[i+1:len(word)])\n",
        "    return del_words"
      ],
      "metadata": {
        "id": "bVpIec7NQ0HM"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_char('poonam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld7CDoKkTotO",
        "outputId": "fc333e73-5422-4238-d191-aad1a5d3b738"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oonam', 'ponam', 'ponam', 'pooam', 'poonm', 'poona']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def switch_char(word):\n",
        "  switch_words = []\n",
        "  for i in range(0,len(word)-1):\n",
        "    switch_words.append(word[:i] + word[i+1] + word[i] + word[i+2:])\n",
        "  return switch_words"
      ],
      "metadata": {
        "id": "ypNTYZLQU1tJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "switch_char('poonam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDk3pDsOaCY3",
        "outputId": "e2bf0a26-7e92-42d0-c3ca-aa68da9cb613"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oponam', 'poonam', 'ponoam', 'pooanm', 'poonma']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_char(word):\n",
        "  alphabet = string.ascii_lowercase\n",
        "  return [word[:i] + c + word[i+1:] for i in range(len(word)) for c in alphabet if c != word[i]]"
      ],
      "metadata": {
        "id": "nM2eHcW5aTxW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_char('can')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91U-iDiUZikr",
        "outputId": "62a2545b-ecb5-41bb-a959-47db21336277"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aan',\n",
              " 'ban',\n",
              " 'dan',\n",
              " 'ean',\n",
              " 'fan',\n",
              " 'gan',\n",
              " 'han',\n",
              " 'ian',\n",
              " 'jan',\n",
              " 'kan',\n",
              " 'lan',\n",
              " 'man',\n",
              " 'nan',\n",
              " 'oan',\n",
              " 'pan',\n",
              " 'qan',\n",
              " 'ran',\n",
              " 'san',\n",
              " 'tan',\n",
              " 'uan',\n",
              " 'van',\n",
              " 'wan',\n",
              " 'xan',\n",
              " 'yan',\n",
              " 'zan',\n",
              " 'cbn',\n",
              " 'ccn',\n",
              " 'cdn',\n",
              " 'cen',\n",
              " 'cfn',\n",
              " 'cgn',\n",
              " 'chn',\n",
              " 'cin',\n",
              " 'cjn',\n",
              " 'ckn',\n",
              " 'cln',\n",
              " 'cmn',\n",
              " 'cnn',\n",
              " 'con',\n",
              " 'cpn',\n",
              " 'cqn',\n",
              " 'crn',\n",
              " 'csn',\n",
              " 'ctn',\n",
              " 'cun',\n",
              " 'cvn',\n",
              " 'cwn',\n",
              " 'cxn',\n",
              " 'cyn',\n",
              " 'czn',\n",
              " 'caa',\n",
              " 'cab',\n",
              " 'cac',\n",
              " 'cad',\n",
              " 'cae',\n",
              " 'caf',\n",
              " 'cag',\n",
              " 'cah',\n",
              " 'cai',\n",
              " 'caj',\n",
              " 'cak',\n",
              " 'cal',\n",
              " 'cam',\n",
              " 'cao',\n",
              " 'cap',\n",
              " 'caq',\n",
              " 'car',\n",
              " 'cas',\n",
              " 'cat',\n",
              " 'cau',\n",
              " 'cav',\n",
              " 'caw',\n",
              " 'cax',\n",
              " 'cay',\n",
              " 'caz']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(replace_char('can'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZgvVVbZazf9",
        "outputId": "ff28a4d5-477a-4077-c692-3873ab3e087a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_char(word):\n",
        "  alphabet = string.ascii_lowercase\n",
        "  return [word[:i] + c + word[i:] for i in range(len(word)+1) for c in alphabet]"
      ],
      "metadata": {
        "id": "FLiX960-bA5_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insert_char('at')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuFRe8vmZexX",
        "outputId": "3d73b821-c93e-4825-a3cf-ef385e77398c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aat',\n",
              " 'bat',\n",
              " 'cat',\n",
              " 'dat',\n",
              " 'eat',\n",
              " 'fat',\n",
              " 'gat',\n",
              " 'hat',\n",
              " 'iat',\n",
              " 'jat',\n",
              " 'kat',\n",
              " 'lat',\n",
              " 'mat',\n",
              " 'nat',\n",
              " 'oat',\n",
              " 'pat',\n",
              " 'qat',\n",
              " 'rat',\n",
              " 'sat',\n",
              " 'tat',\n",
              " 'uat',\n",
              " 'vat',\n",
              " 'wat',\n",
              " 'xat',\n",
              " 'yat',\n",
              " 'zat',\n",
              " 'aat',\n",
              " 'abt',\n",
              " 'act',\n",
              " 'adt',\n",
              " 'aet',\n",
              " 'aft',\n",
              " 'agt',\n",
              " 'aht',\n",
              " 'ait',\n",
              " 'ajt',\n",
              " 'akt',\n",
              " 'alt',\n",
              " 'amt',\n",
              " 'ant',\n",
              " 'aot',\n",
              " 'apt',\n",
              " 'aqt',\n",
              " 'art',\n",
              " 'ast',\n",
              " 'att',\n",
              " 'aut',\n",
              " 'avt',\n",
              " 'awt',\n",
              " 'axt',\n",
              " 'ayt',\n",
              " 'azt',\n",
              " 'ata',\n",
              " 'atb',\n",
              " 'atc',\n",
              " 'atd',\n",
              " 'ate',\n",
              " 'atf',\n",
              " 'atg',\n",
              " 'ath',\n",
              " 'ati',\n",
              " 'atj',\n",
              " 'atk',\n",
              " 'atl',\n",
              " 'atm',\n",
              " 'atn',\n",
              " 'ato',\n",
              " 'atp',\n",
              " 'atq',\n",
              " 'atr',\n",
              " 'ats',\n",
              " 'att',\n",
              " 'atu',\n",
              " 'atv',\n",
              " 'atw',\n",
              " 'atx',\n",
              " 'aty',\n",
              " 'atz']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(insert_char('at'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQE3vdQjHaQn",
        "outputId": "f54c9cf3-19ff-4c05-ba44-00df8e6e94ee"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: : Edit Distance Calculations"
      ],
      "metadata": {
        "id": "Gl39Ar5fQqWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_distance_one(word, allow_switches=False):\n",
        "  edits = []\n",
        "\n",
        "  # Insertion\n",
        "  edits.extend(insert_char(word))\n",
        "\n",
        "  # Deletion\n",
        "  edits.extend(delete_char(word))\n",
        "\n",
        "  # Replacement\n",
        "  edits.extend(replace_char(word))\n",
        "\n",
        "  # Switch (optional)\n",
        "  if allow_switches:\n",
        "    edits.extend(switch_char(word))\n",
        "\n",
        "  return edits\n",
        "\n",
        "def edit_distance_two(word, allow_switches=False):\n",
        "  one_edits = edit_distance_one(word, allow_switches)\n",
        "\n",
        "  # Apply another edit to each one-edit word\n",
        "  two_edits = set()\n",
        "  for one_edit in one_edits:\n",
        "    two_edits.update(edit_distance_one(one_edit, allow_switches))\n",
        "\n",
        "  return two_edits\n"
      ],
      "metadata": {
        "id": "l3I_ZFG0Q0w6"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering redundant edits:\n",
        "\n",
        "* It creates an empty set fixed_edits to store the refined suggestions.\n",
        "* It iterates through each word in the edits set:\n",
        "> * For each word, it calls edit_distance_one(edit) to generate all words that are one edit away from that edit word.\n",
        "> * It checks if the current edit word is already present in the combination of edits set and the generated one-edit words.\n",
        "> * If the edit word is already reachable through a single edit from another word in the set, it's considered redundant and not added to fixed_edits.\n",
        "> * If the edit word is unique and not reachable through a single edit from other words, it's added to fixed_edits\n",
        "\n",
        "\n",
        "If the input edits set is **[\"rane\", \"rain\", \"rainn\"]** and the original word is \"rain\":\n",
        "\n",
        "It would remove \"rainn\" because it's reachable from \"rain\" by inserting an \"n\".\n",
        "It would keep \"rane\" because it's a unique edit (deleting \"i\").\n",
        "\n",
        "The final fixed_edits set would be **[\"rane\", \"rain\"]**\n",
        "\n"
      ],
      "metadata": {
        "id": "PHnoEleeyBKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_edits(edits, original_word):\n",
        "  fixed_edits = set()\n",
        "  for edit in edits:\n",
        "    if edit not in edits.union(edit_distance_one(edit)):\n",
        "      fixed_edits.add(edit)\n",
        "  return fixed_edits"
      ],
      "metadata": {
        "id": "E9RyIzenyKQz"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(edit_distance_one('at', True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ej47lPwt1DI",
        "outputId": "aa602390-5d25-4ab5-a16d-e5f8200fff75"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(edit_distance_two('a', True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njOPkcmYajQz",
        "outputId": "c0c28fec-f44a-43da-b375-18f082b8c211"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2654"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3"
      ],
      "metadata": {
        "id": "8KC6xU1sQqd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_vocabulary(filename):\n",
        "  \"\"\"\n",
        "  Reads a vocabulary of words from a text file.\n",
        "\n",
        "  Args:\n",
        "      filename: The path to the text file.\n",
        "\n",
        "  Returns:\n",
        "      A set of words from the text file.\n",
        "  \"\"\"\n",
        "  vocab = list()\n",
        "  with open(filename, 'r') as f:\n",
        "    for line in f:\n",
        "      # Remove punctuation and split into words\n",
        "      words = line.strip().split()\n",
        "      for word in words:\n",
        "        # Lowercase and add to vocabulary\n",
        "        vocab.append(word.translate(str.maketrans('', '', string.punctuation)).lower())\n",
        "  return vocab\n",
        "\n"
      ],
      "metadata": {
        "id": "1WaoPgLqQ1RT"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Initializes an empty set suggestions to store potential suggestions.\n",
        "* Checks if the word is already in the vocabulary:\n",
        "> * If yes, adds it to the suggestions set.\n",
        "> * If not, generates words with edit distance one and two using edit_distance_one and edit_distance_two functions (not shown in the provided code).\n",
        "* Intersects these generated words with the vocabulary to keep only valid words.\n",
        "* If no valid suggestions are found, adds the original word back to the suggestions set as a last resort.\n",
        "* Calculates probabilities for each suggestion based on their frequency in the vocabulary."
      ],
      "metadata": {
        "id": "n87lQaqvwnV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggestion_algorithm(word, vocab, n):\n",
        "    suggestions = set()\n",
        "    # Generate suggestions\n",
        "    if word in vocab:\n",
        "        suggestions.add(word)\n",
        "    else:\n",
        "        suggestions_one = set(edit_distance_one(word))\n",
        "        suggestions_two = set(edit_distance_two(word))\n",
        "        suggestions.update(suggestions_one.intersection(vocab))\n",
        "        if not suggestions:\n",
        "            suggestions.update(suggestions_two.intersection(vocab))\n",
        "        if not suggestions:\n",
        "            suggestions.add(word)\n",
        "\n",
        "    # Probabilities\n",
        "    total_occurrences = sum((vocab).count(suggestion) for suggestion in suggestions)\n",
        "    best_words = {}\n",
        "    for suggestion in suggestions:\n",
        "        if suggestion in vocab:\n",
        "            probability = (vocab).count(suggestion) / total_occurrences\n",
        "        else:\n",
        "            probability = 0\n",
        "        best_words[suggestion] = probability\n",
        "    # Step 3: Choose top n suggestions\n",
        "    top_suggestions = Counter(best_words).most_common(n)\n",
        "    return top_suggestions\n",
        "\n"
      ],
      "metadata": {
        "id": "6HX-1k0awmhd"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = read_vocabulary('/content/shakespeare.txt')\n",
        "entered_word = 'TOT'\n",
        "suggestions = suggestion_algorithm(entered_word.lower(), vocab, 5)\n",
        "\n",
        "for word, prob in suggestions:\n",
        "  print(f\"word: {word}, probability: {prob}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxMVRrVbsiCN",
        "outputId": "479c94d5-33af-45c6-9cbd-1fd5937d32df"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word: to, probability: 0.68\n",
            "word: not, probability: 0.2783333333333333\n",
            "word: too, probability: 0.03\n",
            "word: got, probability: 0.005\n",
            "word: hot, probability: 0.005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Words are assigned different probabilities based on their edit distance:\n",
        "* Words in the vocabulary: highest weight (1.0)\n",
        "* Words in edit distance one: lower weight (0.7)\n",
        "* Words in edit distance two: even lower weight (0.4)\n",
        "* Original word: lowest weight (0.1)\n",
        "\n",
        "Frequency-based adjustments: Within each edit distance list, the weights are further adjusted based on the word's frequency in the vocabulary. More frequent words have a higher probability within their respective lists.\n",
        "\n",
        "Probability normalization: All probabilities are normalized to ensure they stay within the 0-1 range, regardless of the frequency of words."
      ],
      "metadata": {
        "id": "VBYk-5E8u3y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggestion_algorithm(word, vocab, n):\n",
        "    suggestions = set()\n",
        "\n",
        "    # Generate suggestions with normalized probabilities\n",
        "    if word in vocab:\n",
        "        suggestions.add((word, 1.0))  # Highest weight for words in vocab\n",
        "    else:\n",
        "        suggestions_one = set()\n",
        "        for word_edit in edit_distance_one(word):\n",
        "            if word_edit in vocab:\n",
        "                frequency = vocab.count(word_edit)\n",
        "                probability = min(1.0, 0.7 * frequency)  # Normalize to 1\n",
        "                suggestions_one.add((word_edit, probability))\n",
        "        suggestions_two = set()\n",
        "        for word_edit in edit_distance_two(word):\n",
        "            if word_edit in vocab:\n",
        "                frequency = vocab.count(word_edit)\n",
        "                probability = min(1.0, 0.4 * frequency)  # Normalize to 1\n",
        "                suggestions_two.add((word_edit, probability))\n",
        "        suggestions.update(suggestions_one)\n",
        "        if not suggestions:\n",
        "            suggestions.update(suggestions_two)\n",
        "        if not suggestions:\n",
        "            suggestions.add((word, 0.1))  # Least weight for original word\n",
        "\n",
        "    # Choose top n suggestions based on weighted probability and frequency\n",
        "    top_suggestions = sorted(suggestions, key=lambda x: x[1], reverse=True)[:n]\n",
        "    return top_suggestions"
      ],
      "metadata": {
        "id": "w6nFrJrAr6dP"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = read_vocabulary('/content/shakespeare.txt')\n",
        "entered_word = 'dys'\n",
        "suggestions = suggestion_algorithm(entered_word.lower(), vocab, 2)\n",
        "\n",
        "for word, prob in suggestions:\n",
        "  print(f\"word: {word}, probability: {prob}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w31TMpZ8CtaJ",
        "outputId": "68387f01-e130-4e7c-fde1-3fd173316264"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word: days, probability: 1.0\n",
            "word: dye, probability: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Lvf0Xp6aiLY"
      },
      "execution_count": 84,
      "outputs": []
    }
  ]
}